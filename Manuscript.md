


---
title: "Timing in Admission Yield"
output: word_document
bibliography: Bib_20220818.bib
pandoc_args: ["--filter=pandoc-citeproc"]
---


## Introduction
Motivation
Recruitment of new students is a challenging task of enrollment management for many institutions of higher education, since they need to meet revenue goals, ensure academic ability and promote diversity of the student body [@adams2019higher; @maldonado2017assessing]. The recruitment process includes several general stages, searching and answering inquries of propsective applicants, reviewing application materials and making admission decisions, encouraging admitted students to pay deposits, and assisting with students' matriculation. This project focuses on the deposit stage where students' choices play an important role. Understanding students' decision to pay deposits can help institutions to design marketing and recruitment strategies [@desjardins2002analytic; @johnson2019destinations]. 

Summary of previous studies
Previous studies have investigated various factors which could affect admission outcome and provided insights on improving recruitment efforts. DesJardins [@desjardins2002analytic] used predictive models to segment students, so enrollment managers could focused on groups of interest. Maldonado et al. [@maldonado2017assessing] developed nested logit models to predict students' enrollment probabilities, and the decision makers utilized the models to allocate resources for admission activities. Goenner and Pauls [@goenner2006predictive] predicted the enrollment probabilities of inquirers to help University of North Dakota allocate recruitment efforts by geographic areas. Braunstein et al. [@braunstein1999measuring] focused on the factors related to student financials on enrollment decisions of admitted students, so the particular institution can understand the effects of various financial aids and how they affect students differently from various socio-economic backgrounds. Johnson [@johnson2019destinations] studied various factors associated with enrollment decisions of out-of-state students with multiple potential destinations and provided insights on why the students accepted their offer of admission or chose another instittion.  

Contribution of this study
This study provides new insights on admission outcome to help with recruitment efforts. First, we include time-varing factors with time-varing effects in our event history analysis. Although previous studies investigated the effects of various factors, they implicitly assumed that all factors had time independent values and the correponding effects were also time independent. However, the Admission Office could design better marketing strategies, if they have better understanding on the factors whose effects really fluctuate along the admission season, e.g., what would be the best time to offer institutional financial aid, and when could be more effective to communicate with certain groups of students. Second, we model deposit decisions instead of enrollment decisions. Although enrollment decision is the final outcome of interest, in practice the Admission Office work sequentially to encourage paying deposits and then to prevent withdrawal of deposits (which they call "summer melt"). Third, we include student activities as surrogate of students' interests to the admission offer, in addition to the factors usually included in previous research such as demographic characteristics, socio-economic background, high school academic performance and student financials. More specifically, we investigate the effects            


Summary of results
In this paper, we implement the improved framework to nine fall cohorts of applicants to the University of Delaware, from Fall 2011 to Fall 2020. Our models show high accuracy in terms of the difference between the number of predicted deposits and actual deposits by week. The typical error rate is below 3% or below 150 deposits. The closer a future week is to the current week, the more accurate the prediction is. We show that transfer learning helps to enhance the models' predictive accuracy, by comparing the performance of models before and after being updated from target cohort's information. The increase of accuracy depends on the difference between the cohort used to develop a model and the cohort for testing the model. The impact of transfer learning is trivial, if the difference is neglectable. Otherwise, transfer learning is necessary to guarantee this tool is helpful for institutional planning on tuition revenue from incoming students. The accuracy of predicting fall 2020 is an exception though. Unless April's data are available, the accuracy is low for predicting yield in May no matter how the model configuration is tuned.

## Literature Review
### Admission Funnel
An admission funnel invovles six processes, prospects, inquiries, applicants, admits, deposits and enrolls [@stonybrook]. In the prospect stage, the admission office search for high school students who might be interested to the institution. In the inquiry stage, the admission office communicate with students who expressed interest, attempt to furhter enhance their interest, and encourage them to apply. In the applicant stage, the admission office notify students with incomplete application forms, process and review completed applications. In the admit stage, the admission office make decisions to offer admission, put students on a wait list, or reject applications. In the deposit stage, the admission office prepare financial aid packages and collaborate with other offices to interact with admitted students in campus tours and other programs, in order to encourge the students to accept the offers. In the enroll stage, the admission office continue to engage with students and collaborate with other offices to help with new student orientation, course registration and on-campus residency. There are several important rates to monitor in the admission funnel, conversion rate, selection rate, yield rate and melt rate [@ruffalonl]. Conversion rate is The proportion of applicants from inquiries. Selection rate is the proportion of admits from applicants. Yield rate is the proportion of deposits from admits. Melt rate is the proportion of enrolls from deposits. With melt rate typically closed to 1 or 100% at the University of Delaware, the deposit stage or yield rate largely determines the number of new students we will have.   

### Classical Approach
To predict admission outcome, previous studies have built several statistical and data mining models, with logistic regression being the most popular one. DesJardins built a logistic regression model to predict fall 2001 entering cohort based on data of admitted students in fall 1999 in a large public Research I institution in the Midwest [@desjardins2002analytic]. The predicted enrollment probabilities were used to segment admitted students into ten groups, so the admission office could apply different recruitment and marketing strategies. Goenner and Pauls built a logistic regression model to predict the enrollment probabilities of 15,827 inquirers to the University of North Dakota (UND) for fall 2003 [@goenner2006predictive]. They used Bayesian model averaging to address overfiting from a single model. Their results were used at UND to target prospective students for fall 2006 cohort. Thomas et al. built a logistic regression model to predict the enrollment probabilities of admitted students for cohort fall 1998 [@thomas1999using] in Stony Brook University. They used fall 1996 data to train a model, used fall 1997 data to evaluate the model's performance, and then applied the model to fall 1998 data. They suggested to focus on the students with relatively low enrollment probablities (between 30% and 50%), in order to optimize the impact of the recruitment efforts. Shrestha et al. built various models to predict the enrollment acceptance rate of 24,283 admitted international students at a large metropolican Australian University from 2008 to 2013 [@shrestha2016offer]. Logistic regression and neural network models showed better performance than the other models, including Naive Bayes, decision tree, support vector machines, random forests and k-nearest neighbour. Aulck et al. built various models to predict enrollment probabilities and then applied the results to optimize scholarship disbursement [@aulck2019using] in a large, public university. They found that the emsembled classifiers, randome forest, gradient boosted trees and a bagging tree ensemble perform better than the other models, including K-nearest neighbors, regularized logistic regression, support vector machines, and a neural network with 3 hidden layers. They applied the strategy to domestic non-resident applicants in cohort fall 2018, and the admission yield increased from about 10-12% to 14.8%. 

### Transfer Learning
Transfer learning improves the yied prediction for a target cohort by updating a model built from a source cohort, while in a classical approach the model built from the source cohort is directly applied to the target cohort [@pan2009survey; @weiss2016survey]. That is to say, we build a model from the source cohort with known yield information, update the model according to limited information in the target cohort, and apply the updated model for prediction. The update process can be simultaneous with the source model building [@evgeniou2004regularized] or can be in sequence after the source model is built [@bastani2020predicting]. Evgeniou and Pontil (2004) assumed the source task and target task were related by common parameter w₀ in Support Vector Machine (SVM) models, where w₀ and deviation from w₀ were trained simultaneously using labeled source domain and target domain. With experiments on simulated data and real-world data, the authors claimed that the performance of the model was much better than the SVM models trained individually. Bastani (2020) proposed a two-step transfer learning to de-bias parameters in the target model from the source model. There were abundant labels in the source domain and limited labels in the target domain. Linear regression models were used to implement the two-step approach. The baseline approaches include Ridge regression on target data, linear regression on source data, model averaging with source and target data, and weighted loss estimator with source and target data. The author theoretical and empirically proved that the proposed two-step approach has better predictive performance than all baseline approaches. More importantly, the author realized the difference between source model and target model is sparse, when applying the two-step approach to real-world datasets. As a result, the few features could be identified which cause the bias between the source domain and target domain. For example, the price coefficient is the only feature which has non-neglectable difference in models from customer click data (source) and from customer purchase data (target) in e-commerce platforms, and thus business insight was extracted from the proposed 2-step transfer learning approach.    

## Data and Variables
Admit, deposit and yield trend
Data for this study were pulled from a data reporting platform of the University of Delaware (UD), a public research university (Carnegie classification: R1) with a population of about 18,000 undergraduate students. We collected the weekly admission data of out-of-state applicants between late February and early May from Fall 2012 to Fall 2019. We chose late February as the starting point, because most admission decisions were made by the Admission Office by then and the Budget Office began to review the budget plan for the coming fiscal year. Most students paid deposit in early May if they accepted UD's offer, so we used it as the end point. Table 1 shows the number of admits and deposits by May 1 of each year. The number of admitted out-of-state students gradually increased from about 12,500 to about 15,000 from 2012 to 2019, and the number of deposited out-of-state students fluctuated between 2200 and 2900. Figure 1 shows yield by week for Fall 2017, Fall 2018 and Fall 2019. Week 11 always represents May 1, and Week 1 represents 70 days before May 1, which is in late Feburary. For all three falls, the yields increase slowly in early weeks in February and March, increase faster in April, and jump in the last week of April. The yield trends are more similar between Fall 2017 and Fall 2018, and the gap is larger between the trends of Fall 2018 and Fall 2019. Overall the sequence of week is a strong predictor for yield, and thus is used as an independent variable in the models. 

Student attributes
In addition to the sequence of week, student attributes are also included in the initial list of variables to predict yields. Table 2 describes the dependent and indepent variables in the models, and Table 3 shows the descriptive statistics of the variables. The depedent variable is whether a student will pay deposit. The independent variables include the student's demographic information, high school information, financial background, financial aid information. We further include interaction between financial aid and some other variables such as the interaction between institutional aid rate and estimated family contrbution (EFC) rate, because we suspect the effect of institutional aid rate can be affected by other variables. 

## Variable Selection
From the initial list of predictors, we select a subset with consistently high predictive powers and use them as input of the subsequent models. First, we randomly draw samples with replacement from a fall's data with date being May 1. Second, we fit LASSO regression to predict yield and record which variables are selected and the correpsonding coefficients. Third, we repeat the previous two steps 200 times, so we can calculate the probability of each variable being selected for the fall. The higher the probability is, the higher predictive power a variable has. Fourth, we repeat the previous three steps for each fall, so we know which variables tend to have high predictive powers over years. We select Yield from major, HS GPA, Feeder HS, Institutional aid rate, EFC rate, African American, Asian, White, and Inst\*EFC. Fifth, we exclude variables with high variance of coefficients. Even a variable is selected for each fall, the high variance of coefficient indicates the predictive power is not consistent, so it will hurt the predictive performance when a trained model is applied to a test dataset. In this case, we calculate the average coefficients for selected variables from last step for each fall, and the calculate the standard deviation of the average coefficients. All variables show relatively small standard deviation except Yield from major which has standard deviation larger than 1, so we exclude Yield from major. Therefore, the final list of predictors are HS GPA, Feeder HS, Institutional aid rate, EFC rate, African American, Asian, White, and Inst\*EFC.

## Statistical Model
The statistical model is a combination of an expential survival model and a logistic regression model. Equations (1) to (3) describe the prior distribution of unknown coefficients $\alpha_t$, $\beta_t$ and $\beta_j$, where $j$ is from 1 to 8. 

$$ \alpha_t \sim \mathrm{Normal}(\mu_\alpha, \sigma_\alpha) $$ (1)
$$ \beta_t \sim \mathrm{Normal}(\mu_\beta, \sigma_\beta) $$ (2)
$$ \beta_j \sim \mathrm{Normal}(\mu_j, \sigma_j) $$ (3)
$$ \theta_i = exp(\beta_t*(week_i - \alpha_t)) * (1/(1+exp(-\Sigma_j(\beta_j*X_{ij})))) $$ (4)
$$ y_i \sim \mathrm{Bernoulli}(\theta_i) $$ (5)

## Notes
Three key ideas: combination of exponential survival analysis and logistic regression, transfer learning and rolling projection
Need to define source cohort and target cohort in Introduction
Two exponetial functions, maybe cite the material paper?

## Reference

